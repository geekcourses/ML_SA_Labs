{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Neural Networks with Keras - Basic Concepts\n",
    "\n",
    "## 2. Basic Structure of a Neural Network\n",
    "In Keras, a neural network model is defined using layers that transform input data into desired outputs. \n",
    "Layers are the basic building blocks of neural networks in Keras. A layer consists of a tensor-in tensor-out computation function  and some state, held in TensorFlow variables (the layer's weights).\n",
    "\n",
    "Each layer performs a specific mathematical operation and passes the processed data to the next layer. \n",
    "\n",
    "\n",
    "- **Layers**: Building blocks of neural networks.\n",
    "- **Input Layer**: Receives input data.\n",
    "- **Hidden Layers**: Perform transformations on data.\n",
    "- **Output Layer**: Produces final predictions.\n",
    "\n",
    "\n",
    "### What is a Tensor in Keras?\n",
    "\n",
    "A **tensor** in Keras is a multi-dimensional array that is used to represent data. Tensors can have various shapes and data types, making them the basic building blocks of deep learning models. They are used to define inputs, outputs, weights, and activations within neural networks.\n",
    "\n",
    "Tensors are simmilar to numpay arrays, but can leverage parallel processing on GPUs through deep learning frameworks like TensorFlow and PyTorch, making them highly efficient for large-scale computations in neural networks.\n",
    "\n",
    "#### Key Points:\n",
    "1. **Multi-Dimensional Array**: A tensor can be a scalar (0D), vector (1D), matrix (2D), or higher-dimensional array (3D, 4D, etc.).\n",
    "2. **Shape**: Defined by the number of dimensions and the size of each dimension. For example:\n",
    "   - `Scalar`: Shape `()`\n",
    "   - `Vector`: Shape `(3,)`\n",
    "   - `Matrix`: Shape `(3, 4)`\n",
    "   - `4D Tensor`: Shape `(batch_size, height, width, channels)`\n",
    "3. **Data Types**: Tensors can have different data types, such as `float32`, `int32`, etc.\n",
    "4. **Manipulation**: Tensors support various operations like addition, multiplication, reshaping, and slicing.\n",
    "\n",
    "#### Tensor Example in Keras:\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Creating a 2D tensor (Matrix)\n",
    "tensor_example = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(tensor_example)\n",
    "\n",
    "\n",
    "# Output:\n",
    "# <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
    "# array([[1., 2.],\n",
    "#        [3., 4.]], dtype=float32)>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining a Simple Neural Network in Keras\n",
    "\n",
    "There are multiple ways to build a model in Keras depending on the complexity and structure of the neural network.\n",
    "\n",
    "### 3.1 Sequential Model\n",
    "\n",
    "The **Sequential** model is a linear stack of layers, where each layer has exactly one input and one output. It is used for simple feed-forward architectures without branching or skipping connections.\n",
    "\n",
    "**Example: Simple Feed-Forward Network**\n",
    "```python\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define a sequential model\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(input_dim,)),  # Input and Hidden Layer 1\n",
    "    Dense(16, activation='relu'),                            # Hidden Layer 2\n",
    "    Dense(1, activation='sigmoid')                           # Output Layer\n",
    "])\n",
    "```\n",
    "\n",
    "### 3.2 Functional API\n",
    "\n",
    "The **Functional API** in Keras is more flexible than the Sequential model, allowing for complex architectures such as multi-input, multi-output models, or models with shared layers. Instead of stacking layers linearly, the Functional API enables defining models by connecting layers like a graph, which provides greater control over the network structure.\n",
    "\n",
    "- **Define Input Layer**: Start by defining the input layer using `Input()`.\n",
    "- **Connect Layers**: Use layer instances (e.g., `Dense`) and connect them using function calls.\n",
    "- **Create the Model**: Pass the input and output layers to the `Model()` class.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "# Define the input layer\n",
    "inputs = Input(shape=(input_dim,))\n",
    "\n",
    "# Define the layers\n",
    "x1 = Dense(32, activation='relu')(inputs)   # Hidden Layer 1\n",
    "x2 = Dense(16, activation='relu')(x1)       # Hidden Layer 2\n",
    "outputs = Dense(1, activation='sigmoid')(x2) # Output Layer\n",
    "\n",
    "# Create the model using the Functional API\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "```\n",
    "\n",
    "### 3.3 Model Subclassing\n",
    "\n",
    "**Model Subclassing** provides maximum flexibility and customization for building neural networks in Keras. It involves creating a custom class that inherits from the `tf.keras.Model` class and defining the network layers and their forward pass within the class. This approach is particularly useful when building complex models that require dynamic behavior or custom training loops.\n",
    "\n",
    "- **Create a Custom Class**: Inherit from `tf.keras.Model` and define layers in the `__init__` method.\n",
    "- **Define the Forward Pass**: Implement the `call()` method, which specifies how the data flows through the layers.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define a custom model by subclassing tf.keras.Model\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.dense1 = Dense(32, activation='relu')   # Hidden Layer 1\n",
    "        self.dense2 = Dense(16, activation='relu')   # Hidden Layer 2\n",
    "        self.out = Dense(1, activation='sigmoid')    # Output Layer\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.out(x)\n",
    "\n",
    "# Instantiate and build the custom model\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Popular Artificial Neural Network Types Supported by Keras\n",
    "\n",
    "1. **Feed-Forward Neural Network (FFNN)**  \n",
    "   - **Keras Class**: `tensorflow.keras.layers.Dense`\n",
    "   - Basic architecture where data flows in one direction without cycles.\n",
    "   - Suitable for general-purpose tasks like tabular data classification and regression.\n",
    "\n",
    "2. **Convolutional Neural Network (CNN)**  \n",
    "   - **Keras Class**: `tensorflow.keras.layers.Conv2D`, `tensorflow.keras.layers.MaxPooling2D`\n",
    "   - Designed for image-related tasks like image classification, object detection, and segmentation.\n",
    "   - Uses convolutional and pooling layers to detect spatial patterns.\n",
    "\n",
    "   <a href=\"./images/Convolutional-Neural-Networks.webp\"><img src='./images/Convolutional-Neural-Networks.webp' style=height:12em></a><br>\n",
    "   *Image source: https://learnopencv.com/understanding-feedforward-neural-networks/*\n",
    "   \n",
    "3. **Recurrent Neural Network (RNN)**  \n",
    "   - **Keras Class**: `tensorflow.keras.layers.SimpleRNN`\n",
    "   - Designed for sequential data like time series, text, and audio.\n",
    "   - Capable of maintaining state and capturing temporal dependencies.\n",
    "\n",
    "   <a href=\"./images/FFNN.jpg\"><img src='./images/FFNN.jpg' style=height:12em></a><br>\n",
    "   *Image source: https://learnopencv.com/understanding-convolutional-neural-networks-cnn/*\n",
    "\n",
    "4. **Long Short-Term Memory (LSTM)**  \n",
    "   - **Keras Class**: `tensorflow.keras.layers.LSTM`\n",
    "   - An advanced type of RNN that solves the vanishing gradient problem.\n",
    "   - Effective for learning long-term dependencies in sequences.\n",
    "\n",
    "5. **Gated Recurrent Unit (GRU)**  \n",
    "   - **Keras Class**: `tensorflow.keras.layers.GRU`\n",
    "   - A simplified version of LSTMs with fewer parameters.\n",
    "   - Faster to train and performs well on sequential tasks.\n",
    "\n",
    "6. **Transformer Networks**  \n",
    "   - **Keras Class**: `tensorflow.keras.layers.MultiHeadAttention`, `tensorflow.keras.layers.Transformer`\n",
    "   - Based on self-attention mechanisms.\n",
    "   - Highly effective for NLP tasks such as machine translation and text summarization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compilation of the Model\n",
    "\n",
    "Model compilation is a crucial step that defines how the model learns and optimizes its weights. During compilation, the optimizer, loss function, and evaluation metrics are specified. These parameters determine how the model will be trained and evaluated.\n",
    "\n",
    "### Key Components:\n",
    "1. **Optimizer**:\n",
    "   - Controls how the model updates its weights during training.\n",
    "   - Common optimizers: `adam`, `sgd`, `rmsprop`.\n",
    "   - Example: `optimizer='adam'`\n",
    "\n",
    "2. **Loss Function**:\n",
    "   - Measures the difference between the true labels and model predictions.\n",
    "   - For classification: `binary_crossentropy`, `categorical_crossentropy`.\n",
    "   - For regression: `mean_squared_error`.\n",
    "   - Example: `loss='binary_crossentropy'`\n",
    "\n",
    "3. **Metrics**:\n",
    "   - Used to evaluate the model's performance during training and testing.\n",
    "   - Common metrics: `accuracy`, `precision`, `recall`.\n",
    "   - Example: `metrics=['accuracy']`\n",
    "\n",
    "### Example: Model Compilation\n",
    "```python\n",
    "# Compile the model with optimizer, loss function, and metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "`optimizer='adam'`: Uses the Adam optimizer, which is a popular choice due to its adaptive learning rate and efficient performance.\n",
    "\n",
    "`loss='binary_crossentropy'`: Specifies the loss function for binary classification tasks.\n",
    "\n",
    "`metrics=['accuracy']`: Sets the evaluation metric to track the accuracy of the model during training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the Model\n",
    "\n",
    "Training a model in Keras is done using the `fit` method. This method performs forward and backward passes through the network, updates the model weights based on the loss function, and monitors performance metrics over multiple epochs. During training, you can also specify data validation to track the modelâ€™s progress on unseen data.\n",
    "\n",
    "### Key Parameters of the `fit` Method:\n",
    "1. **x**: Input data (e.g., training features).\n",
    "2. **y**: Target labels corresponding to the input data.\n",
    "3. **epochs**: Number of complete passes through the entire training dataset.\n",
    "4. **batch_size**: Number of samples per gradient update. Smaller batches use less memory but may result in less stable updates.\n",
    "5. **validation_split**: Fraction of training data to be used for validation (e.g., `0.2` for 20% validation data).\n",
    "6. **callbacks**: List of callback functions to monitor the training (e.g., early stopping, model checkpointing).\n",
    "\n",
    "### Example: Training a Simple Model\n",
    "```python\n",
    "# Train the model using the fit method\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=20,                 # Number of epochs to train the model\n",
    "                    batch_size=32,             # Number of samples per batch\n",
    "                    validation_split=0.2)      # Use 20% of the data for validation\n",
    "\n",
    "```\n",
    "\n",
    "*Explanation*:\n",
    "\n",
    "`epochs=20`: The model will train for 20 complete passes over the training data.\n",
    "\n",
    "`batch_size=32`: For each update, 32 samples will be processed before updating the model weights.\n",
    "\n",
    "`validation_split=0`.2: Keras will reserve 20% of the training data for validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating the Model\n",
    "\n",
    "After training, the model needs to be evaluated to assess its performance on unseen test data. In Keras, this is done using the `evaluate` method, which computes the loss and other metrics defined during model compilation.\n",
    "\n",
    "### Key Points:\n",
    "- **Purpose**: Measure how well the model generalizes to new data.\n",
    "- **Output**: Returns the loss value and any other specified metrics, such as accuracy.\n",
    "\n",
    "### Parameters of the `evaluate` Method:\n",
    "1. **x**: Test features or input data (e.g., `x_test`).\n",
    "2. **y**: Test labels corresponding to the input data (e.g., `y_test`).\n",
    "3. **batch_size**: Number of samples per batch. Defaults to 32.\n",
    "4. **verbose**: Verbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch).\n",
    "\n",
    "### Example: Evaluating a Model on Test Data\n",
    "```python\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, batch_size=32, verbose=1)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "```\n",
    "\n",
    "*Explanation*:\n",
    "\n",
    "`x_test, y_test`: Test dataset used for evaluation.\n",
    "\n",
    "`test_loss`: The loss value calculated on the test set.\n",
    "\n",
    "`test_accuracy`: The accuracy of the model on the test set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Predicting with the Model\n",
    "\n",
    "## 7. Predicting with the Model\n",
    "\n",
    "Once the model is trained and evaluated, it can be used to make predictions on new, unseen data. This is done using the `predict` method in Keras, which returns the predicted values for the input data.\n",
    "\n",
    "### Key Points:\n",
    "- **Purpose**: To generate predictions on new data (e.g., class labels, probabilities, or regression values).\n",
    "- **Output**: Returns an array of predicted values based on the model's learned weights.\n",
    "\n",
    "### Parameters of the `predict` Method:\n",
    "1. **x**: Input data for which predictions are to be made (e.g., `x_new`).\n",
    "2. **batch_size**: Number of samples per batch. Defaults to 32.\n",
    "3. **verbose**: Verbosity mode (0 = silent, 1 = progress bar).\n",
    "\n",
    "### Example: Making Predictions on New Data\n",
    "```python\n",
    "# Predict on new input data\n",
    "predictions = model.predict(x_new, batch_size=32, verbose=1)\n",
    "print(predictions)\n",
    "```\n",
    "\n",
    "*Explanation*:\n",
    "\n",
    "`x_new`: New data samples for which predictions are to be made.\n",
    "\n",
    "`predictions`: Array of predicted values (e.g., class probabilities or labels).\n",
    "\n",
    "For a classifier, predict returns probabilities for each class. You can use argmax to get the predicted class label.\n",
    "\n",
    "```python\n",
    "predicted_classes = predictions.argmax(axis=-1)\n",
    "print(predicted_classes)\n",
    "```\n",
    "\n",
    "Regression: For a regression model, it returns the predicted numerical value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
