{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers for Spam/Ham classification\n",
    "\n",
    "## Problem Description\n",
    "\n",
    "The goal is to build a machine learning model to classify emails as spam or not spam. \n",
    "\n",
    "## Data Description and Analyses\n",
    "\n",
    "The dataset is taken from https://www.kaggle.com/datasets/ozlerhakan/spam-or-not-spam-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>martin a posted tassos papadopoulos the greek ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>man threatens explosion in moscow thursday aug...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>thank you for shopping with us gifts for all ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>the famous ebay marketing e course learn to s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>hello this is chinese traditional 子 件 NUMBER世...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  email  label\n",
       "0      date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
       "1     martin a posted tassos papadopoulos the greek ...      0\n",
       "2     man threatens explosion in moscow thursday aug...      0\n",
       "2997   thank you for shopping with us gifts for all ...      1\n",
       "2998   the famous ebay marketing e course learn to s...      1\n",
       "2999   hello this is chinese traditional 子 件 NUMBER世...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load teh data\n",
    "data = pd.read_csv('../datasets/spam_or_not_spam.csv')\n",
    "\n",
    "# see first and last 3 rows\n",
    "pd.concat([data.head(3), data.tail(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    2500\n",
       "1     500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the occurrences of 0 and 1 in the 'label' column\n",
    "label_counts = data['label'].value_counts()\n",
    "label_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "email    1\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for NA values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 3,000 entries, with 2,500 labeled as non-spam (0) and 500 labeled as spam (1). \n",
    "There is one row with a missing value in the 'email' column, which will be removed to ensure data consistency.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove row with NA in email:\n",
    "data.dropna(subset=['email'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2399,)\n",
      "(2399,)\n",
      "(600,)\n",
      "(600,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['email'], data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert text data into TF-IDF features\n",
    "\n",
    "TF-IDF transformer must be fitted only on the training data, to avoid data leakage. This mimics real-world scenarios where the model only has access to training data and must generalize to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Tune Classifiers Using GridSearchCV\n",
    "\n",
    "We will train and evaluate three different Naive Bayes classifiers to identify the most effective one for this classification task.\n",
    "\n",
    "Note: GaussianNB requires a dense matrix, whereas MultinomialNB and BernoulliNB can efficiently work with sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise classifiers and parameters for grid search\n",
    "models = [\n",
    "    {\n",
    "        'name': 'GaussianNB',\n",
    "        'classifier': GaussianNB(),\n",
    "        'param_grid': {'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]}\n",
    "    },\n",
    "    {\n",
    "        'name': 'MultinomialNB',\n",
    "        'classifier': MultinomialNB(),\n",
    "        'param_grid': {'alpha': [0.1, 0.5, 1.0, 1.5, 2.0]}\n",
    "    },\n",
    "    {\n",
    "        'name': 'BernoulliNB',\n",
    "        'classifier': BernoulliNB(),\n",
    "        'param_grid': {'alpha': [0.1, 0.5, 1.0, 1.5, 2.0], 'binarize': [0.0, 0.5, 1.0]}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for: GaussianNB\n",
      "Best parameters for GaussianNB: {'var_smoothing': 1e-05}\n",
      "Best F1 score for GaussianNB: 0.8646142721397524\n",
      "Accuracy for GaussianNB: 0.9716666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       500\n",
      "           1       0.94      0.89      0.91       100\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.96      0.94      0.95       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "--------------------------------------------------\n",
      "Tuning hyperparameters for: MultinomialNB\n",
      "Best parameters for MultinomialNB: {'alpha': 0.1}\n",
      "Best F1 score for MultinomialNB: 0.9399704785554219\n",
      "Accuracy for MultinomialNB: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       500\n",
      "           1       1.00      0.94      0.97       100\n",
      "\n",
      "    accuracy                           0.99       600\n",
      "   macro avg       0.99      0.97      0.98       600\n",
      "weighted avg       0.99      0.99      0.99       600\n",
      "\n",
      "--------------------------------------------------\n",
      "Tuning hyperparameters for: BernoulliNB\n",
      "Best parameters for BernoulliNB: {'alpha': 0.1, 'binarize': 0.0}\n",
      "Best F1 score for BernoulliNB: 0.8674300708175536\n",
      "Accuracy for BernoulliNB: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       500\n",
      "           1       0.98      0.84      0.90       100\n",
      "\n",
      "    accuracy                           0.97       600\n",
      "   macro avg       0.97      0.92      0.94       600\n",
      "weighted avg       0.97      0.97      0.97       600\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train and Test each classifier\n",
    "for model in models:\n",
    "    print(f'Tuning hyperparameters for: {model[\"name\"]}')\n",
    "\n",
    "    # Convert sparse arrays to dense for GaussianNB\n",
    "    if model['name'] == 'GaussianNB':\n",
    "        X_train = X_train.toarray()\n",
    "        X_test = X_test.toarray()\n",
    "\n",
    "\n",
    "    # Perform GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model['classifier'],\n",
    "        param_grid=model['param_grid'],\n",
    "        cv=5, scoring='f1'\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best parameters and score\n",
    "    print(f'Best parameters for {model[\"name\"]}: {grid_search.best_params_}')\n",
    "    print(f'Best F1 score for {model[\"name\"]}: {grid_search.best_score_}')\n",
    "\n",
    "    # use the best estimator to predict on the test set\n",
    "    best_clf = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate on the test set (assuming X_test is already split and prepared)\n",
    "    y_pred = best_clf.predict(X_test)\n",
    "\n",
    "    # Print evaluation metrics\n",
    "    print(f'Accuracy for {model[\"name\"]}: {accuracy_score(y_test, y_pred)}')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print('-' * 50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
